{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 1820,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.27472527472527475,
      "grad_norm": 0.06123390793800354,
      "learning_rate": 0.0002919230769230769,
      "loss": 1.7395,
      "step": 50
    },
    {
      "epoch": 0.5494505494505495,
      "grad_norm": 0.05382345989346504,
      "learning_rate": 0.0002836813186813186,
      "loss": 0.2255,
      "step": 100
    },
    {
      "epoch": 0.8241758241758241,
      "grad_norm": 0.034314513206481934,
      "learning_rate": 0.0002754395604395604,
      "loss": 0.1985,
      "step": 150
    },
    {
      "epoch": 1.098901098901099,
      "grad_norm": 0.03306465968489647,
      "learning_rate": 0.0002671978021978022,
      "loss": 0.1974,
      "step": 200
    },
    {
      "epoch": 1.3736263736263736,
      "grad_norm": 0.024991843849420547,
      "learning_rate": 0.00025895604395604396,
      "loss": 0.1849,
      "step": 250
    },
    {
      "epoch": 1.6483516483516483,
      "grad_norm": 0.029277410358190536,
      "learning_rate": 0.0002507142857142857,
      "loss": 0.175,
      "step": 300
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 0.028832189738750458,
      "learning_rate": 0.00024247252747252747,
      "loss": 0.1869,
      "step": 350
    },
    {
      "epoch": 2.197802197802198,
      "grad_norm": 0.0298844613134861,
      "learning_rate": 0.0002342307692307692,
      "loss": 0.1776,
      "step": 400
    },
    {
      "epoch": 2.4725274725274726,
      "grad_norm": 0.030593739822506905,
      "learning_rate": 0.00022598901098901098,
      "loss": 0.1748,
      "step": 450
    },
    {
      "epoch": 2.7472527472527473,
      "grad_norm": 0.032710008323192596,
      "learning_rate": 0.00021774725274725272,
      "loss": 0.177,
      "step": 500
    },
    {
      "epoch": 3.021978021978022,
      "grad_norm": 0.034777767956256866,
      "learning_rate": 0.00020950549450549446,
      "loss": 0.1701,
      "step": 550
    },
    {
      "epoch": 3.2967032967032965,
      "grad_norm": 0.03417269140481949,
      "learning_rate": 0.00020126373626373623,
      "loss": 0.1701,
      "step": 600
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.04179038479924202,
      "learning_rate": 0.00019302197802197803,
      "loss": 0.1615,
      "step": 650
    },
    {
      "epoch": 3.8461538461538463,
      "grad_norm": 0.039136290550231934,
      "learning_rate": 0.00018478021978021977,
      "loss": 0.1721,
      "step": 700
    },
    {
      "epoch": 4.1208791208791204,
      "grad_norm": 0.04459163919091225,
      "learning_rate": 0.00017653846153846154,
      "loss": 0.1754,
      "step": 750
    },
    {
      "epoch": 4.395604395604396,
      "grad_norm": 0.040184568613767624,
      "learning_rate": 0.00016829670329670328,
      "loss": 0.1703,
      "step": 800
    },
    {
      "epoch": 4.670329670329671,
      "grad_norm": 0.04431988671422005,
      "learning_rate": 0.00016005494505494505,
      "loss": 0.1593,
      "step": 850
    },
    {
      "epoch": 4.945054945054945,
      "grad_norm": 0.03833964839577675,
      "learning_rate": 0.0001518131868131868,
      "loss": 0.1555,
      "step": 900
    },
    {
      "epoch": 5.21978021978022,
      "grad_norm": 0.04619712382555008,
      "learning_rate": 0.00014357142857142856,
      "loss": 0.1572,
      "step": 950
    },
    {
      "epoch": 5.4945054945054945,
      "grad_norm": 0.03883771598339081,
      "learning_rate": 0.00013532967032967033,
      "loss": 0.1679,
      "step": 1000
    },
    {
      "epoch": 5.769230769230769,
      "grad_norm": 0.03474561497569084,
      "learning_rate": 0.00012708791208791207,
      "loss": 0.1656,
      "step": 1050
    },
    {
      "epoch": 6.043956043956044,
      "grad_norm": 0.04036847501993179,
      "learning_rate": 0.00011884615384615383,
      "loss": 0.1571,
      "step": 1100
    },
    {
      "epoch": 6.318681318681318,
      "grad_norm": 0.04186028614640236,
      "learning_rate": 0.0001106043956043956,
      "loss": 0.162,
      "step": 1150
    },
    {
      "epoch": 6.593406593406593,
      "grad_norm": 0.03962593525648117,
      "learning_rate": 0.00010236263736263735,
      "loss": 0.1563,
      "step": 1200
    },
    {
      "epoch": 6.868131868131869,
      "grad_norm": 0.045968230813741684,
      "learning_rate": 9.412087912087911e-05,
      "loss": 0.1643,
      "step": 1250
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.04929812625050545,
      "learning_rate": 8.587912087912086e-05,
      "loss": 0.1598,
      "step": 1300
    },
    {
      "epoch": 7.417582417582418,
      "grad_norm": 0.044731877744197845,
      "learning_rate": 7.763736263736263e-05,
      "loss": 0.1573,
      "step": 1350
    },
    {
      "epoch": 7.6923076923076925,
      "grad_norm": 0.0441790334880352,
      "learning_rate": 6.939560439560439e-05,
      "loss": 0.1543,
      "step": 1400
    },
    {
      "epoch": 7.967032967032967,
      "grad_norm": 0.04402606934309006,
      "learning_rate": 6.115384615384614e-05,
      "loss": 0.1583,
      "step": 1450
    },
    {
      "epoch": 8.241758241758241,
      "grad_norm": 0.04204666242003441,
      "learning_rate": 5.291208791208791e-05,
      "loss": 0.1631,
      "step": 1500
    },
    {
      "epoch": 8.516483516483516,
      "grad_norm": 0.04409284144639969,
      "learning_rate": 4.467032967032967e-05,
      "loss": 0.1476,
      "step": 1550
    },
    {
      "epoch": 8.791208791208792,
      "grad_norm": 0.046681199222803116,
      "learning_rate": 3.6428571428571423e-05,
      "loss": 0.1526,
      "step": 1600
    },
    {
      "epoch": 9.065934065934066,
      "grad_norm": 0.04503875970840454,
      "learning_rate": 2.8186813186813186e-05,
      "loss": 0.1649,
      "step": 1650
    },
    {
      "epoch": 9.340659340659341,
      "grad_norm": 0.056272510439157486,
      "learning_rate": 1.9945054945054945e-05,
      "loss": 0.1526,
      "step": 1700
    },
    {
      "epoch": 9.615384615384615,
      "grad_norm": 0.042556848376989365,
      "learning_rate": 1.1703296703296702e-05,
      "loss": 0.1591,
      "step": 1750
    },
    {
      "epoch": 9.89010989010989,
      "grad_norm": 0.04623694717884064,
      "learning_rate": 3.4615384615384613e-06,
      "loss": 0.1625,
      "step": 1800
    }
  ],
  "logging_steps": 50,
  "max_steps": 1820,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.52760928960512e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}

{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 2070,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.2418379685610641,
      "grad_norm": 0.046935006976127625,
      "learning_rate": 0.00029304347826086954,
      "loss": 1.3212,
      "step": 50
    },
    {
      "epoch": 0.4836759371221282,
      "grad_norm": 0.021475747227668762,
      "learning_rate": 0.0002857971014492753,
      "loss": 0.1902,
      "step": 100
    },
    {
      "epoch": 0.7255139056831923,
      "grad_norm": 0.03124150261282921,
      "learning_rate": 0.00027855072463768115,
      "loss": 0.191,
      "step": 150
    },
    {
      "epoch": 0.9673518742442564,
      "grad_norm": 0.022744160145521164,
      "learning_rate": 0.00027130434782608693,
      "loss": 0.1778,
      "step": 200
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.17676277458667755,
      "eval_runtime": 20.9353,
      "eval_samples_per_second": 35.156,
      "eval_steps_per_second": 4.394,
      "step": 207
    },
    {
      "epoch": 1.2079806529625152,
      "grad_norm": 0.034981075674295425,
      "learning_rate": 0.0002640579710144927,
      "loss": 0.168,
      "step": 250
    },
    {
      "epoch": 1.4498186215235793,
      "grad_norm": 0.029109882190823555,
      "learning_rate": 0.00025681159420289855,
      "loss": 0.1664,
      "step": 300
    },
    {
      "epoch": 1.6916565900846434,
      "grad_norm": 0.025398747995495796,
      "learning_rate": 0.0002495652173913043,
      "loss": 0.1647,
      "step": 350
    },
    {
      "epoch": 1.9334945586457075,
      "grad_norm": 0.028786946088075638,
      "learning_rate": 0.00024231884057971013,
      "loss": 0.1493,
      "step": 400
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.16335244476795197,
      "eval_runtime": 21.0029,
      "eval_samples_per_second": 35.043,
      "eval_steps_per_second": 4.38,
      "step": 414
    },
    {
      "epoch": 2.1741233373639663,
      "grad_norm": 0.034080568701028824,
      "learning_rate": 0.00023507246376811594,
      "loss": 0.1614,
      "step": 450
    },
    {
      "epoch": 2.4159613059250304,
      "grad_norm": 0.03854576498270035,
      "learning_rate": 0.00022782608695652172,
      "loss": 0.1519,
      "step": 500
    },
    {
      "epoch": 2.657799274486094,
      "grad_norm": 0.03511101379990578,
      "learning_rate": 0.00022057971014492753,
      "loss": 0.1513,
      "step": 550
    },
    {
      "epoch": 2.8996372430471586,
      "grad_norm": 0.03156980872154236,
      "learning_rate": 0.00021333333333333333,
      "loss": 0.1474,
      "step": 600
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.15676036477088928,
      "eval_runtime": 20.9114,
      "eval_samples_per_second": 35.196,
      "eval_steps_per_second": 4.4,
      "step": 621
    },
    {
      "epoch": 3.140266021765417,
      "grad_norm": 0.03804965689778328,
      "learning_rate": 0.0002060869565217391,
      "loss": 0.1513,
      "step": 650
    },
    {
      "epoch": 3.382103990326481,
      "grad_norm": 0.03442675620317459,
      "learning_rate": 0.00019884057971014492,
      "loss": 0.1441,
      "step": 700
    },
    {
      "epoch": 3.6239419588875452,
      "grad_norm": 0.03787239268422127,
      "learning_rate": 0.00019159420289855073,
      "loss": 0.155,
      "step": 750
    },
    {
      "epoch": 3.8657799274486093,
      "grad_norm": 0.03851647302508354,
      "learning_rate": 0.0001843478260869565,
      "loss": 0.1381,
      "step": 800
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.15348604321479797,
      "eval_runtime": 20.9119,
      "eval_samples_per_second": 35.195,
      "eval_steps_per_second": 4.399,
      "step": 828
    },
    {
      "epoch": 4.106408706166868,
      "grad_norm": 0.03881675377488136,
      "learning_rate": 0.0001771014492753623,
      "loss": 0.1445,
      "step": 850
    },
    {
      "epoch": 4.348246674727933,
      "grad_norm": 0.04891284927725792,
      "learning_rate": 0.00016985507246376812,
      "loss": 0.1462,
      "step": 900
    },
    {
      "epoch": 4.590084643288996,
      "grad_norm": 0.04267369955778122,
      "learning_rate": 0.00016260869565217393,
      "loss": 0.1483,
      "step": 950
    },
    {
      "epoch": 4.831922611850061,
      "grad_norm": 0.04298128932714462,
      "learning_rate": 0.00015536231884057968,
      "loss": 0.1347,
      "step": 1000
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.15140791237354279,
      "eval_runtime": 21.0032,
      "eval_samples_per_second": 35.042,
      "eval_steps_per_second": 4.38,
      "step": 1035
    },
    {
      "epoch": 5.072551390568319,
      "grad_norm": 0.0440317839384079,
      "learning_rate": 0.00014811594202898549,
      "loss": 0.1447,
      "step": 1050
    },
    {
      "epoch": 5.314389359129383,
      "grad_norm": 0.04531744122505188,
      "learning_rate": 0.0001408695652173913,
      "loss": 0.1379,
      "step": 1100
    },
    {
      "epoch": 5.556227327690447,
      "grad_norm": 0.04384702816605568,
      "learning_rate": 0.0001336231884057971,
      "loss": 0.1403,
      "step": 1150
    },
    {
      "epoch": 5.798065296251512,
      "grad_norm": 0.03935401886701584,
      "learning_rate": 0.0001263768115942029,
      "loss": 0.1435,
      "step": 1200
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.1499791145324707,
      "eval_runtime": 20.9821,
      "eval_samples_per_second": 35.078,
      "eval_steps_per_second": 4.385,
      "step": 1242
    },
    {
      "epoch": 6.03869407496977,
      "grad_norm": 0.03901871666312218,
      "learning_rate": 0.00011913043478260869,
      "loss": 0.1319,
      "step": 1250
    },
    {
      "epoch": 6.280532043530834,
      "grad_norm": 0.04102664440870285,
      "learning_rate": 0.00011188405797101449,
      "loss": 0.1361,
      "step": 1300
    },
    {
      "epoch": 6.522370012091899,
      "grad_norm": 0.053425997495651245,
      "learning_rate": 0.00010463768115942027,
      "loss": 0.1404,
      "step": 1350
    },
    {
      "epoch": 6.764207980652962,
      "grad_norm": 0.05409972369670868,
      "learning_rate": 9.739130434782606e-05,
      "loss": 0.1346,
      "step": 1400
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.14914865791797638,
      "eval_runtime": 21.0373,
      "eval_samples_per_second": 34.985,
      "eval_steps_per_second": 4.373,
      "step": 1449
    },
    {
      "epoch": 7.004836759371221,
      "grad_norm": 0.045976314693689346,
      "learning_rate": 9.014492753623187e-05,
      "loss": 0.1408,
      "step": 1450
    },
    {
      "epoch": 7.246674727932286,
      "grad_norm": 0.044190555810928345,
      "learning_rate": 8.289855072463766e-05,
      "loss": 0.1435,
      "step": 1500
    },
    {
      "epoch": 7.488512696493349,
      "grad_norm": 0.056970857083797455,
      "learning_rate": 7.565217391304347e-05,
      "loss": 0.1301,
      "step": 1550
    },
    {
      "epoch": 7.730350665054414,
      "grad_norm": 0.050627049058675766,
      "learning_rate": 6.840579710144926e-05,
      "loss": 0.1257,
      "step": 1600
    },
    {
      "epoch": 7.9721886336154775,
      "grad_norm": 0.0456484891474247,
      "learning_rate": 6.115942028985507e-05,
      "loss": 0.1429,
      "step": 1650
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.14857906103134155,
      "eval_runtime": 20.975,
      "eval_samples_per_second": 35.089,
      "eval_steps_per_second": 4.386,
      "step": 1656
    },
    {
      "epoch": 8.212817412333736,
      "grad_norm": 0.0428178571164608,
      "learning_rate": 5.3913043478260865e-05,
      "loss": 0.1308,
      "step": 1700
    },
    {
      "epoch": 8.4546553808948,
      "grad_norm": 0.04670069366693497,
      "learning_rate": 4.6666666666666665e-05,
      "loss": 0.1374,
      "step": 1750
    },
    {
      "epoch": 8.696493349455865,
      "grad_norm": 0.05496647208929062,
      "learning_rate": 3.9420289855072465e-05,
      "loss": 0.1447,
      "step": 1800
    },
    {
      "epoch": 8.938331318016928,
      "grad_norm": 0.040732961148023605,
      "learning_rate": 3.217391304347826e-05,
      "loss": 0.1291,
      "step": 1850
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.1482415646314621,
      "eval_runtime": 20.952,
      "eval_samples_per_second": 35.128,
      "eval_steps_per_second": 4.391,
      "step": 1863
    },
    {
      "epoch": 9.178960096735187,
      "grad_norm": 0.04925825819373131,
      "learning_rate": 2.4927536231884055e-05,
      "loss": 0.1258,
      "step": 1900
    },
    {
      "epoch": 9.420798065296252,
      "grad_norm": 0.04895319789648056,
      "learning_rate": 1.768115942028985e-05,
      "loss": 0.1357,
      "step": 1950
    },
    {
      "epoch": 9.662636033857316,
      "grad_norm": 0.05756622180342674,
      "learning_rate": 1.0434782608695651e-05,
      "loss": 0.1312,
      "step": 2000
    },
    {
      "epoch": 9.904474002418379,
      "grad_norm": 0.05598976090550423,
      "learning_rate": 3.188405797101449e-06,
      "loss": 0.1414,
      "step": 2050
    }
  ],
  "logging_steps": 50,
  "max_steps": 2070,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1.755118684864512e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
